import os
import pandas as pd
import re
from sqlalchemy import create_engine
from sqlalchemy.sql import text
from rapidfuzz import process


# é…ç½®æ•°æ®åº“è¿æ¥
engine = create_engine("mysql+pymysql://shop:shop12345@localhost:3306/shop_db?charset=utf8mb4")

# æ¸…ç©ºæ—§æ•°æ®
with engine.begin() as conn:
    conn.execute(text("SET FOREIGN_KEY_CHECKS=0;"))
    conn.execute(text("DELETE FROM order_item"))
    conn.execute(text("DELETE FROM orders"))
    conn.execute(text("DELETE FROM product_spec"))
    conn.execute(text("DELETE FROM product"))
    conn.execute(text("DELETE FROM region"))
    conn.execute(text("DELETE FROM customer"))
    conn.execute(text("DELETE FROM category"))
    conn.execute(text("SET FOREIGN_KEY_CHECKS=1;"))
print("å·²æ¸…ç©ºæ—§æ•°æ®ï¼Œå‡†å¤‡å¯¼å…¥æ–°æ•°æ®...")

# å®šä½æ–‡ä»¶è·¯å¾„
base_dir = os.path.dirname(os.path.abspath(__file__))
orders_csv_path = os.path.join(base_dir, '../database/è®¢å•æ•°æ®-7.13.csv')
products_excel_path = os.path.join(base_dir, '../database/å•†å“åˆ—è¡¨.xlsx')

# è¯»å–æ•°æ®
print("å¼€å§‹è¯»å– CSV å’Œ Excel æ–‡ä»¶...")
df_orders = pd.read_csv(orders_csv_path, encoding='utf-8')
df_products = pd.read_excel(products_excel_path, sheet_name='å•†å“åº“å•†å“')
df_specs = pd.read_excel(products_excel_path, sheet_name='ä¼šå‘˜ä»·')
print("æ–‡ä»¶è¯»å–æˆåŠŸã€‚")


# åˆ†ç±»å­—æ®µç»Ÿä¸€ç©ºå€¼å¤„ç† + å»ç©ºæ ¼
for col in ['ä¸€çº§åˆ†ç±»', 'äºŒçº§åˆ†ç±»', 'ä¸‰çº§åˆ†ç±»']:
    df_products[col] = df_products[col].fillna('').astype(str).str.strip()

print("å¯¼å…¥ category è¡¨...")

# æŒ‰ä¸‰çº§åˆ†ç±»å»é‡ï¼Œç”Ÿæˆåˆ†ç±»è¡¨
df_categories = df_products[['ä¸€çº§åˆ†ç±»', 'äºŒçº§åˆ†ç±»', 'ä¸‰çº§åˆ†ç±»']].drop_duplicates().copy()

# ç”Ÿæˆå”¯ä¸€ CategoryIDï¼Œæ¯”å¦‚ C001, C002, ...
df_categories['CategoryID'] = ['C' + str(i+1).zfill(3) for i in range(len(df_categories))]

# é‡å‘½åå­—æ®µ
df_categories.rename(columns={
    'ä¸€çº§åˆ†ç±»': 'Category1',
    'äºŒçº§åˆ†ç±»': 'Category2',
    'ä¸‰çº§åˆ†ç±»': 'Category3'
}, inplace=True)

# å¯¼å…¥ category è¡¨
df_categories.to_sql('category', con=engine, if_exists='append', index=False)

print(f' category è¡¨å¯¼å…¥å®Œæˆï¼Œå…± {len(df_categories)} æ¡ã€‚')

# ------------------------

print("å¯¼å…¥ product è¡¨...")

# å•†å“å”¯ä¸€ ID
df_products['ProductID'] = df_products['å•†å“id'].astype(str)

# å»ºç«‹åˆ†ç±»æ˜ å°„è¡¨
category_map = df_categories.set_index(['Category1', 'Category2', 'Category3'])['CategoryID']

# ç»™å•†å“è¡¨åŠ  CategoryID
df_products['CategoryID'] = df_products.apply(
    lambda row: category_map.get((row['ä¸€çº§åˆ†ç±»'], row['äºŒçº§åˆ†ç±»'], row['ä¸‰çº§åˆ†ç±»'])),
    axis=1
)

# æ£€æŸ¥ç¼ºå¤±
missing_count = df_products['CategoryID'].isnull().sum()
if missing_count > 0:
    print(f" æœ‰ {missing_count} ä¸ªå•†å“æœªåŒ¹é…åˆ° CategoryIDï¼Œå»ºè®®æ£€æŸ¥åˆ†ç±»æ•°æ®ï¼")
    print(df_products[df_products['CategoryID'].isnull()][['ProductID', 'ä¸€çº§åˆ†ç±»', 'äºŒçº§åˆ†ç±»', 'ä¸‰çº§åˆ†ç±»']].head())

    # å¯é€‰ï¼šä¸¢å¼ƒè¿™äº›å•†å“
    df_products = df_products.dropna(subset=['CategoryID'])
    print(f"å·²ä¸¢å¼ƒæœªåŒ¹é…åˆ°åˆ†ç±»çš„å•†å“ï¼Œå‰©ä½™ {len(df_products)} æ¡ã€‚")

# é‡å‘½åå­—æ®µ
df_products.rename(columns={
    'å•†å“åç§°': 'ProductName',
    'é”€é‡': 'Sales',
    'ä¸€çº§å“ç‰Œ': 'Brand1',
    'äºŒçº§å“ç‰Œ': 'Brand2',
}, inplace=True)

# å»é‡åå¯¼å…¥
df_products_unique = df_products.drop_duplicates(subset=['ProductID'])

df_products_unique[['ProductID', 'CategoryID', 'ProductName', 'Sales', 'Brand1', 'Brand2']].to_sql(
    'product', con=engine, if_exists='append', index=False
)

print(f' product è¡¨å¯¼å…¥å®Œæˆï¼Œå…± {len(df_products_unique)} æ¡ï¼ˆå»é‡åï¼‰ã€‚')



print("å¯¼å…¥ product_spec è¡¨...")

df_products['ProdSpecID'] = df_products['è§„æ ¼id'].astype(str)
df_products['ProductID'] = df_products['å•†å“id'].astype(str)
df_products['SpecName'] = df_products['è§„æ ¼é¡¹1'].astype(str)
df_products['Price'] = df_products['é›¶å”®ä»·'].fillna(0).astype(float)
df_products['Weight'] = df_products['é‡é‡'].fillna(100).astype(float)

df_products[['ProdSpecID', 'ProductID', 'SpecName', 'Price', 'Weight']].to_sql(
    'product_spec', con=engine, if_exists='append', index=False)

print(f'product_spec è¡¨å¯¼å…¥å®Œæˆï¼Œå…± {len(df_products)} æ¡ã€‚')

# å¯¼å…¥ customer è¡¨
print("å¯¼å…¥ customer è¡¨...")

# --- æ•°æ®æ¸…æ´—å’Œé¢„å¤„ç† ---
# ç¡®ä¿å…³é”®å­—æ®µä¸ºå­—ç¬¦ä¸²å¹¶å»é™¤å‰åç©ºæ ¼
df_orders['ä¹°å®¶æ˜µç§°'] = df_orders['ä¹°å®¶æ˜µç§°'].astype(str).str.strip()
df_orders['ä¸‹å•æ¬¡æ•°'] = df_orders['ä¸‹å•æ¬¡æ•°'].astype(str).str.strip()

# å¤„ç†ä¼šå‘˜ç­‰çº§åˆ—çš„æ··åˆç±»å‹é—®é¢˜
# ä¸ºäº†èƒ½å®‰å…¨åœ°ä½¿ç”¨ .transform('max')ï¼Œæˆ‘ä»¬å…ˆå°†ç©ºå€¼(NaN)æ›¿æ¢ä¸ºç©ºå­—ç¬¦ä¸² ''
# ç„¶åå†å°†æ•´åˆ—å¼ºåˆ¶è½¬æ¢ä¸ºå­—ç¬¦ä¸²ç±»å‹ã€‚ç©ºå­—ç¬¦ä¸² '' åœ¨æ¯”è¾ƒæ—¶ä¼šè¢«æ‰€æœ‰æœ‰æ•ˆç­‰çº§ï¼ˆå¦‚'2_1'ï¼‰è§†ä¸ºâ€œæœ€å°â€
df_orders['ä¼šå‘˜ç­‰çº§'] = df_orders['ä¼šå‘˜ç­‰çº§'].fillna('').astype(str).str.strip()


# --- è®¡ç®—æ¯ä¸ªå®¢æˆ·çš„æœ€å¤§ä¸‹å•æ¬¡æ•° ---
# ä»â€œä¸‹å•æ¬¡æ•°â€ä¸­æå–æ•°å­—ï¼Œå¹¶è½¬æ¢ä¸ºæ•´æ•°
df_orders['order_count_num'] = pd.to_numeric(
    df_orders['ä¸‹å•æ¬¡æ•°'].str.extract(r'(\d+)', expand=False),
    errors='coerce'
).fillna(0).astype(int)
# æŒ‰å®¢æˆ·åˆ†ç»„ï¼Œè®¡ç®—æœ€å¤§ä¸‹å•æ¬¡æ•°
df_orders['actual_order_count'] = df_orders.groupby('ä¹°å®¶æ˜µç§°')['order_count_num'].transform('max')


# --- è®¡ç®—æ¯ä¸ªå®¢æˆ·çš„æœ€é«˜ä¼šå‘˜ç­‰çº§ ---
# ç°åœ¨è¯¥åˆ—å·²æ— æ··åˆç±»å‹ï¼Œå¯ä»¥å®‰å…¨åœ°è®¡ç®—æœ€å¤§å€¼
df_orders['actual_member_level'] = df_orders.groupby('ä¹°å®¶æ˜µç§°')['ä¼šå‘˜ç­‰çº§'].transform('max')


df_customers = df_orders[[
    'ä¹°å®¶æ˜µç§°', 'ä¹°å®¶å§“å', 'ä¹°å®¶æ‰‹æœºå·', 'actual_member_level', 'ä¹°å®¶æ˜¯å¦ä¼šå‘˜',
    'å®¢æˆ·æ ‡ç­¾', 'ä¹°å®¶å¤‡æ³¨', 'actual_order_count'
]].copy()

# é‡å‘½åå­—æ®µä»¥åŒ¹é…æ•°æ®åº“
df_customers.rename(columns={
    'ä¹°å®¶æ˜µç§°': 'Customer_ID',
    'ä¹°å®¶å§“å': 'Name',
    'ä¹°å®¶æ‰‹æœºå·': 'Phone',
    'actual_member_level': 'MemberLevel',
    'ä¹°å®¶æ˜¯å¦ä¼šå‘˜': 'IsMember',
    'å®¢æˆ·æ ‡ç­¾': 'Tags',
    'ä¹°å®¶å¤‡æ³¨': 'Remark',
    'actual_order_count':'order_count'
}, inplace=True)

# å»æ‰é‡å¤å®¢æˆ·ï¼Œç°åœ¨æ¯ä¸ªå®¢æˆ·çš„ 'order_count' å’Œ 'MemberLevel' éƒ½å·²æ˜¯å…¶æ­£ç¡®çš„å€¼
df_customers = df_customers.drop_duplicates(subset=['Customer_ID'], keep='last')

# å°†å¤„ç†è¿‡ç¨‹ä¸­äº§ç”Ÿçš„ç©ºå­—ç¬¦ä¸² '' è½¬æ¢å› None
# None åœ¨ to_sql ä¸­ä¼šè¢«æ­£ç¡®åœ°è½¬æ¢æˆæ•°æ®åº“çš„ NULL å€¼
import numpy as np
df_customers['MemberLevel'].replace('', np.nan, inplace=True)


# å°†å¤„ç†å¥½çš„æ•°æ®å­˜å…¥æ•°æ®åº“
# to_sql ä¼šè‡ªåŠ¨å°† pandas ä¸­çš„ np.nan (NaN) å†™å…¥æ•°æ®åº“çš„ NULL
df_customers.to_sql('customer', con=engine, if_exists='append', index=False)
print(f' customer è¡¨å¯¼å…¥å®Œæˆï¼Œå…± {len(df_customers)} æ¡ã€‚')

# å¯¼å…¥ region è¡¨
print("å¯¼å…¥ region è¡¨...")

# åœ°å€å­—æ®µç©ºå€¼å¤„ç†
for col in ['æ”¶è´§äººçœä»½', 'æ”¶è´§äººåŸå¸‚', 'æ”¶è´§äººåœ°åŒº']:
    df_orders[col] = df_orders[col].fillna('').astype(str).str.strip()

df_orders['ä¹°å®¶æ˜µç§°'] = df_orders['ä¹°å®¶æ˜µç§°'].astype(str).str.strip()

df_regions = df_orders[['æ”¶è´§äººçœä»½', 'æ”¶è´§äººåŸå¸‚', 'æ”¶è´§äººåœ°åŒº', 'ä¹°å®¶æ˜µç§°']].drop_duplicates().copy()

df_regions['Customer_ID'] = df_regions['ä¹°å®¶æ˜µç§°']
df_regions.drop(columns=['ä¹°å®¶æ˜µç§°'], inplace=True)

df_regions['RegionID'] = ['R' + str(i+1).zfill(3) for i in range(len(df_regions))]

df_regions.rename(columns={
    'æ”¶è´§äººçœä»½': 'Province',
    'æ”¶è´§äººåŸå¸‚': 'City',
    'æ”¶è´§äººåœ°åŒº': 'District'
}, inplace=True)

df_regions.to_sql('region', con=engine, if_exists='append', index=False)
print(f' region è¡¨å¯¼å…¥å®Œæˆï¼Œå…± {len(df_regions)} æ¡ã€‚')

# å¯¼å…¥ orders è¡¨
print("å¯¼å…¥ orders è¡¨...")

df_orders_main = df_orders[['è®¢å•å·', 'ä¹°å®¶æ˜µç§°', 'è®¢å•çŠ¶æ€', 'è®¢å•åˆ›å»ºæ—¶é—´','ä¹°å®¶ä»˜æ¬¾æ—¶é—´','äº¤æ˜“æˆåŠŸæ—¶é—´','å…¨éƒ¨å•†å“åç§°','å•†å“ç§ç±»æ•°','è®¢å•å•†å“æ€»ä»¶æ•°','è¿è´¹','åº—é“ºä¼˜æƒ åˆè®¡', 'å•†å“é‡‘é¢åˆè®¡']].copy()


# åŠ  Customer_ID å­—æ®µ
df_orders_main['Customer_ID'] = df_orders_main['ä¹°å®¶æ˜µç§°'].astype(str).str.strip()

# ç»™è®¢å•åŠ  RegionIDï¼šæ ¹æ®çœå¸‚åŒº+å®¢æˆ·åŒ¹é…
region_map = df_regions.set_index(['Province', 'City', 'District', 'Customer_ID'])['RegionID']

df_orders_main['Province'] = df_orders['æ”¶è´§äººçœä»½']
df_orders_main['City'] = df_orders['æ”¶è´§äººåŸå¸‚']
df_orders_main['District'] = df_orders['æ”¶è´§äººåœ°åŒº']

df_orders_main['RegionID'] = df_orders_main.apply(
    lambda row: region_map.get((row['Province'], row['City'], row['District'], row['Customer_ID'])),
    axis=1
)


# é‡å‘½å
df_orders_main.rename(columns={
    'è®¢å•å·': 'OrderID',
    'è®¢å•çŠ¶æ€': 'Status',
    'è®¢å•åˆ›å»ºæ—¶é—´': 'Created_time',
    'ä¹°å®¶ä»˜æ¬¾æ—¶é—´': 'Payment_time',
    'äº¤æ˜“æˆåŠŸæ—¶é—´': 'Completed_time',
    'è¿è´¹': 'Freight',
    'åº—é“ºä¼˜æƒ åˆè®¡':'Discount',
    'å•†å“é‡‘é¢åˆè®¡': 'TotalAmount',
    'å…¨éƒ¨å•†å“åç§°':'AllProduct',
    'å•†å“ç§ç±»æ•°':'Pdnumber',
    'è®¢å•å•†å“æ€»ä»¶æ•°':'Totalnumber',
}, inplace=True)

# å»æ‰ä¸´æ—¶åˆ—
df_orders_main.drop(columns=['Province', 'City', 'District', 'ä¹°å®¶æ˜µç§°'], inplace=True)
df_orders_main.to_sql('orders', con=engine, if_exists='append', index=False)
print(f' orders è¡¨å¯¼å…¥å®Œæˆï¼Œå…± {len(df_orders_main)} æ¡ã€‚')


# ============ è‡ªå®šä¹‰æ˜ å°„è¡¨ =============
product_name_map = {
    'æ‹Œæ¿ç­‹': 'ç‰›æ¿ç­‹',
    'æ‹Œç‰›æ¿ç­‹': 'ç‰›æ¿ç­‹',
    'æ‹Œæ¿ç­‹ç‰‡': 'ç‰›æ¿ç­‹',
    'æ‹Œæ¿ç­‹ä¸': 'ç‰›æ¿ç­‹',
}

spec_name_map = {
    'æ‹Œæ¿ç­‹ä¸250g': 'æ¿ç­‹ä¸250g',
    'æ‹Œæ¿ç­‹ç‰‡250g': 'æ¿ç­‹ç‰‡250g',
    'æ‹Œæ¿ç­‹ç‰‡500g': 'æ¿ç­‹ç‰‡500g',
    'æ‹Œæ¿ç­‹ä¸': 'æ¿ç­‹ä¸250g',
    'æ‹Œæ¿ç­‹ç‰‡': 'æ¿ç­‹ç‰‡250g',
}


def clean_text(text):
    if pd.isna(text):
        return ''
    text = ''.join([chr(ord(c)-0xfee0) if 'ï¼' <= c <= 'ï½' else c for c in text])
    text = text.strip().lower()
    text = re.sub(r'[\s\u3000]+', '', text)
    return text

def extract_qty_from_spec(spec_str):
    if not spec_str:
        return '', 1
    spec_str = spec_str.strip()
    if re.match(r'^\d+(\.\d+)?[kKgG][gG]$', spec_str):
        return spec_str, 1
    qty_match = re.search(r'(\d+)\s*è¢‹', spec_str)
    qty = int(qty_match.group(1)) if qty_match else 1
    spec_cleaned = re.sub(r'(\d+)\s*è¢‹', '', spec_str).strip()
    return spec_cleaned, qty

def extract_package_items(item_str):
    if pd.isna(item_str) or not item_str.strip():
        return []

    all_brackets = re.findall(r'\((.*?)\)', item_str)
    product_part = item_str.strip()
    package_qty = 1
    spec_str = None

    if len(all_brackets) >= 2:
        # å•†å“å(è§„æ ¼)(æ•°é‡)
        spec_str = all_brackets[-2].strip()
        qty_match = re.search(r'(\d+)', all_brackets[-1])
        package_qty = int(qty_match.group(1)) if qty_match else 1
        product_part = item_str[:item_str.rfind('(' + all_brackets[-2] + ')')].strip()

    elif len(all_brackets) == 1:
        possible_qty = re.match(r'^(\d+)\s*(è¢‹|ä»¶|ç“¶|ç›’)?$', all_brackets[0].strip())
        if possible_qty:
            package_qty = int(possible_qty.group(1))
            product_part = item_str[:item_str.rfind('(' + all_brackets[0] + ')')].strip()

            # åœ¨å•†å“åéƒ¨åˆ†å°è¯•æå–è§„æ ¼ï¼Œå¦‚500g
            spec_match = re.search(r'(\d+(?:\.\d+)?\s*[kKgG][gG])', product_part)
            if spec_match:
                spec_str = spec_match.group(1).replace(' ','').lower()
                product_part = product_part.replace(spec_match.group(1), '').strip()
            else:
                spec_str = None
        else:
            spec_str = all_brackets[0].strip()
            product_part = item_str[:item_str.rfind('(' + all_brackets[0] + ')')].strip()
    else:
        spec_str = None
        product_part = item_str.strip()

    product_names = [p.strip() for p in re.split(r'\s*\+\s*', product_part)]
    spec_names_raw = [s.strip() for s in re.split(r'\s*\+\s*', spec_str)] if spec_str else [None]*len(product_names)
    while len(spec_names_raw) < len(product_names):
        spec_names_raw.append(None)

    items = []
    for pname, sname_raw in zip(product_names, spec_names_raw):
        if sname_raw:
            spec_cleaned, spec_qty = extract_qty_from_spec(sname_raw)
            final_qty = package_qty * spec_qty
        else:
            spec_cleaned = ''
            final_qty = package_qty
        items.append((pname, spec_cleaned, final_qty))

    return items

def fuzzy_match_spec_for_banjin(spec_name, candidates, threshold=90):
    if not spec_name:
        return None
    result = process.extractOne(spec_name, candidates, score_cutoff=threshold)
    if result:
        match, score, _ = result
        return match
    else:
        return None

def import_order_items(df_orders, df_products):
    print("å¯¼å…¥ order_item è¡¨...")

    df_items = df_orders[['è®¢å•å·', 'å…¨éƒ¨å•†å“åç§°']].copy()
    df_items['å•†å“æ¡ç›®'] = df_items['å…¨éƒ¨å•†å“åç§°'].str.split(';')
    df_items = df_items.explode('å•†å“æ¡ç›®').reset_index(drop=True)

    expanded_rows = []
    for idx, row in df_items.iterrows():
        order_id = row['è®¢å•å·']
        item_str = row['å•†å“æ¡ç›®']
        extracted_items = extract_package_items(item_str)
        for pname_raw, sname_raw, qty in extracted_items:
            pname_mapped = product_name_map.get(pname_raw, pname_raw)
            sname_mapped = spec_name_map.get(sname_raw, sname_raw)

            pname_clean = clean_text(pname_mapped)
            sname_clean = clean_text(sname_mapped)

            if 'ç‰›æ¿ç­‹' in pname_clean:
                candidates = df_products[df_products['ProductName'].str.strip().str.lower() == 'ç‰›æ¿ç­‹']['SpecName'].dropna().unique()
                candidates_cleaned = [clean_text(spec) for spec in candidates]
                matched_spec = fuzzy_match_spec_for_banjin(sname_clean, candidates_cleaned, threshold=90)
                if matched_spec:
                    sname_clean = matched_spec

            expanded_rows.append({
                'è®¢å•å·': order_id,
                'ProductName': pname_clean,
                'SpecName': sname_clean,
                'Quantity': qty
            })

    df_expanded = pd.DataFrame(expanded_rows)

    # Clean productè¡¨
    df_products['ProductName_cleaned'] = df_products['ProductName'].apply(lambda x: clean_text(product_name_map.get(x, x)))
    df_products['SpecName_cleaned'] = df_products['SpecName'].fillna('').apply(lambda x: clean_text(spec_name_map.get(x, x)))

    # å¼ºåˆ¶ SpecName ç©ºå€¼å˜ ''
    df_expanded['SpecName'] = df_expanded['SpecName'].fillna('').astype(str).str.strip()

    df_items_with_spec = df_expanded[df_expanded['SpecName'] != ''].copy()
    df_items_no_spec = df_expanded[df_expanded['SpecName'] == ''].copy()

    df_items_with_spec = df_items_with_spec.merge(
        df_products[['ProdSpecID', 'ProductName_cleaned', 'SpecName_cleaned']],
        left_on=['ProductName', 'SpecName'], right_on=['ProductName_cleaned', 'SpecName_cleaned'], how='left')

    df_items_no_spec = df_items_no_spec.merge(
        df_products[['ProdSpecID', 'ProductName_cleaned']],
        left_on='ProductName', right_on='ProductName_cleaned', how='left')

    df_merged = pd.concat([df_items_with_spec, df_items_no_spec], ignore_index=True)

    unmatched = df_merged[df_merged['ProdSpecID'].isnull()][['ProductName', 'SpecName']].drop_duplicates()
    if not unmatched.empty:
        print(f"âš ï¸ ä»¥ä¸‹å•†å“æœªåŒ¹é…åˆ° ProdSpecIDï¼š\n{unmatched}")
        unmatched.to_excel('æœªåŒ¹é…å•†å“.xlsx', index=False)
        print("ğŸ“¦ æœªåŒ¹é…å•†å“å·²å¯¼å‡ºåˆ°ï¼šæœªåŒ¹é…å•†å“.xlsx")

    df_merged['OrderItemID'] = ['OI' + str(i + 1).zfill(5) for i in range(len(df_merged))]
    df_merged.rename(columns={'è®¢å•å·': 'OrderID'}, inplace=True)
    df_final = df_merged[['OrderItemID', 'OrderID', 'ProdSpecID', 'Quantity']]

    # å†™å…¥æ•°æ®åº“
    df_final.to_sql('order_item', con=engine, if_exists='append', index=False)
    print(f'âœ… order_item è¡¨å¯¼å…¥å®Œæˆï¼Œå…± {len(df_final)} æ¡ã€‚')


# æœ€åæ‰§è¡Œ
import_order_items(df_orders, df_products)



print("å…¨éƒ¨å¯¼å…¥å®Œæˆã€‚")


